"""
Test script for Increment 4: NLP Entity Extraction
"""

import sys
from pathlib import Path

# Add backend directory to path
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from app.services.entity_extractor import EntityExtractor, SPACY_AVAILABLE
from app.models import ExtractedEntities


def test_entity_extractor_initialization():
    """Test EntityExtractor initialization."""
    print("=" * 60)
    print("Testing EntityExtractor Initialization")
    print("=" * 60)
    
    extractor = EntityExtractor()
    
    print(f"\n‚úì EntityExtractor initialized")
    print(f"  - Model: {extractor.model_name}")
    print(f"  - spaCy available: {SPACY_AVAILABLE}")
    print(f"  - Model loaded: {extractor.is_available()}")
    
    if not extractor.is_available():
        print("\n‚ö†Ô∏è  spaCy model not loaded")
        print("   To install: python -m spacy download en_core_web_sm")
        print("   This is optional for Increment 4 but recommended")
    
    print("\n‚úÖ Initialization test passed!")


def test_entity_extraction():
    """Test entity extraction from sample text."""
    print("\n" + "=" * 60)
    print("Testing Entity Extraction")
    print("=" * 60)
    
    extractor = EntityExtractor()
    
    # Sample news article text
    sample_text = """
    Breaking News: Protest in Mumbai
    
    On Monday, thousands of protesters gathered in Mumbai, India to demand 
    climate action. The demonstration was organized by Greenpeace and attended 
    by environmental activist Greta Thunberg. The protest took place at Gateway 
    of India and lasted from 10 AM to 5 PM.
    
    Prime Minister Narendra Modi addressed the concerns, stating that the 
    government is committed to renewable energy. Microsoft and Google have 
    also pledged support for environmental initiatives in the region.
    
    The event was covered by BBC News, Reuters, and The Times of India.
    Similar protests occurred in Delhi, Bangalore, and Chennai on December 1, 2025.
    """
    
    print("\nüìÑ Sample Text:")
    print(sample_text[:200] + "...")
    
    # Extract entities
    entities = extractor.extract_entities(sample_text)
    
    print(f"\n‚úì Entity extraction completed")
    print(f"\nüìä Extracted Entities:")
    
    if entities.persons:
        print(f"\n  üë§ Persons ({len(entities.persons)}):")
        for person in entities.persons[:5]:
            print(f"     - {person}")
    
    if entities.organizations:
        print(f"\n  üè¢ Organizations ({len(entities.organizations)}):")
        for org in entities.organizations[:5]:
            print(f"     - {org}")
    
    if entities.locations:
        print(f"\n  üìç Locations ({len(entities.locations)}):")
        for loc in entities.locations[:5]:
            print(f"     - {loc}")
    
    if entities.dates:
        print(f"\n  üìÖ Dates ({len(entities.dates)}):")
        for date in entities.dates[:5]:
            print(f"     - {date}")
    
    if entities.events:
        print(f"\n  üéØ Events ({len(entities.events)}):")
        for event in entities.events[:3]:
            print(f"     - {event}")
    
    # Test count
    total = extractor.count_entities(entities)
    print(f"\n  Total entities: {total}")
    
    # Verify extraction worked (if spaCy is available)
    if extractor.is_available():
        assert len(entities.persons) > 0 or len(entities.organizations) > 0, \
            "Should extract at least some entities"
        print("\n‚úÖ Entity extraction test passed!")
    else:
        print("\n‚ö†Ô∏è  spaCy not available - skipping validation")
        print("‚úÖ Test passed (limited mode)")


def test_deduplication():
    """Test entity deduplication."""
    print("\n" + "=" * 60)
    print("Testing Entity Deduplication")
    print("=" * 60)
    
    extractor = EntityExtractor()
    
    # Create sample entities with duplicates
    entities1 = ExtractedEntities(
        persons=["John Doe", "Jane Smith"],
        organizations=["Microsoft", "Google"],
        locations=["Mumbai", "Delhi"]
    )
    
    entities2 = ExtractedEntities(
        persons=["John Doe", "Bob Johnson"],  # Duplicate "John Doe"
        organizations=["Google", "Apple"],     # Duplicate "Google"
        locations=["Delhi", "Bangalore"]       # Duplicate "Delhi"
    )
    
    print("\nüìã Entity Set 1:")
    print(f"   Persons: {entities1.persons}")
    print(f"   Organizations: {entities1.organizations}")
    print(f"   Locations: {entities1.locations}")
    
    print("\nüìã Entity Set 2:")
    print(f"   Persons: {entities2.persons}")
    print(f"   Organizations: {entities2.organizations}")
    print(f"   Locations: {entities2.locations}")
    
    # Deduplicate
    merged = extractor.deduplicate_entities([entities1, entities2])
    
    print("\n‚úì Deduplication completed")
    print(f"\nüìä Merged & Deduplicated:")
    print(f"   Persons: {merged.persons}")
    print(f"   Organizations: {merged.organizations}")
    print(f"   Locations: {merged.locations}")
    
    # Verify deduplication
    assert len(merged.persons) == 3, "Should have 3 unique persons"
    assert len(merged.organizations) == 3, "Should have 3 unique organizations"
    assert len(merged.locations) == 3, "Should have 3 unique locations"
    
    print("\n‚úÖ Deduplication test passed!")


def test_article_extraction():
    """Test extraction from article title and content."""
    print("\n" + "=" * 60)
    print("Testing Article Extraction")
    print("=" * 60)
    
    extractor = EntityExtractor()
    
    title = "Tech Giants Meet in Silicon Valley for AI Summit"
    content = """
    Leaders from Microsoft, Google, and Apple gathered in Palo Alto, California
    for the annual AI Summit on November 15, 2025. CEO Satya Nadella delivered
    the keynote address, discussing the future of artificial intelligence.
    
    The three-day conference attracted over 5,000 attendees from around the world,
    including researchers from Stanford University and MIT. Topics included
    machine learning, neural networks, and ethical AI development.
    """
    
    print(f"\nüì∞ Article Title:")
    print(f"   {title}")
    print(f"\nüìÑ Article Content (excerpt):")
    print(f"   {content[:150]}...")
    
    # Extract from article
    entities = extractor.extract_from_article(title, content)
    
    print(f"\n‚úì Extraction from article completed")
    print(f"\nüìä Entities Found:")
    print(f"   Persons: {len(entities.persons)}")
    print(f"   Organizations: {len(entities.organizations)}")
    print(f"   Locations: {len(entities.locations)}")
    print(f"   Dates: {len(entities.dates)}")
    
    if extractor.is_available():
        print(f"\n  Details:")
        if entities.persons:
            print(f"    Persons: {', '.join(entities.persons[:3])}")
        if entities.organizations:
            print(f"    Organizations: {', '.join(entities.organizations[:3])}")
        if entities.locations:
            print(f"    Locations: {', '.join(entities.locations[:3])}")
    
    print("\n‚úÖ Article extraction test passed!")


def test_top_entities():
    """Test getting top N entities."""
    print("\n" + "=" * 60)
    print("Testing Top Entities Selection")
    print("=" * 60)
    
    extractor = EntityExtractor()
    
    # Create entities with many items
    entities = ExtractedEntities(
        persons=[f"Person {i}" for i in range(1, 21)],  # 20 persons
        organizations=[f"Org {i}" for i in range(1, 16)],  # 15 orgs
        locations=[f"Location {i}" for i in range(1, 11)]  # 10 locations
    )
    
    print(f"\nüìä Original counts:")
    print(f"   Persons: {len(entities.persons)}")
    print(f"   Organizations: {len(entities.organizations)}")
    print(f"   Locations: {len(entities.locations)}")
    
    # Get top 5 of each
    top_entities = extractor.get_top_entities(entities, max_per_type=5)
    
    print(f"\n‚úì Top 5 entities selected")
    print(f"\nüìä Top entities counts:")
    print(f"   Persons: {len(top_entities.persons)}")
    print(f"   Organizations: {len(top_entities.organizations)}")
    print(f"   Locations: {len(top_entities.locations)}")
    
    # Verify
    assert len(top_entities.persons) == 5, "Should have 5 persons"
    assert len(top_entities.organizations) == 5, "Should have 5 organizations"
    assert len(top_entities.locations) == 5, "Should have 5 locations"
    
    print("\n‚úÖ Top entities test passed!")


def test_empty_and_edge_cases():
    """Test edge cases."""
    print("\n" + "=" * 60)
    print("Testing Edge Cases")
    print("=" * 60)
    
    extractor = EntityExtractor()
    
    # Test empty text
    print("\n‚úì Testing empty text...")
    entities = extractor.extract_entities("")
    assert extractor.count_entities(entities) == 0
    print("   Empty text handled correctly")
    
    # Test None handling
    print("\n‚úì Testing whitespace-only text...")
    entities = extractor.extract_entities("   \n  \t  ")
    assert extractor.count_entities(entities) == 0
    print("   Whitespace-only text handled correctly")
    
    # Test very short text
    print("\n‚úì Testing very short text...")
    entities = extractor.extract_entities("Hi")
    # Should not crash
    print("   Short text handled correctly")
    
    print("\n‚úÖ Edge cases test passed!")


def main():
    """Run all tests."""
    print("\n" + "=" * 60)
    print("INCREMENT 4 VERIFICATION")
    print("NLP Entity Extraction")
    print("=" * 60)
    
    try:
        # Run all tests
        test_entity_extractor_initialization()
        test_entity_extraction()
        test_deduplication()
        test_article_extraction()
        test_top_entities()
        test_empty_and_edge_cases()
        
        print("\n" + "=" * 60)
        print("‚úÖ INCREMENT 4 COMPLETE - ALL TESTS PASSED!")
        print("=" * 60)
        print("\nDeliverables:")
        print("  ‚úì EntityExtractor service implemented")
        print("  ‚úì Named entity extraction (persons, orgs, locations, dates)")
        print("  ‚úì Entity deduplication working")
        print("  ‚úì Article extraction from title + content")
        print("  ‚úì Top N entities selection")
        print("  ‚úì Edge cases handled")
        
        extractor = EntityExtractor()
        if extractor.is_available():
            print("\nspaCy Status:")
            print(f"  ‚úì Model loaded: {extractor.model_name}")
            print("  ‚úì Ready for production use")
        else:
            print("\nspaCy Status:")
            print("  ‚ö†Ô∏è  Model not loaded (optional)")
            print("  ‚ÑπÔ∏è  To install: python -m spacy download en_core_web_sm")
            print("  ‚ÑπÔ∏è  Entity extraction will work once model is downloaded")
        
        print("\nFeatures:")
        print("  ‚Ä¢ spaCy-based NER (6 entity types)")
        print("  ‚Ä¢ Automatic deduplication")
        print("  ‚Ä¢ Graceful fallback when spaCy unavailable")
        print("  ‚Ä¢ Support for title + content extraction")
        print("  ‚Ä¢ Top N entity selection")
        print("  ‚Ä¢ Comprehensive error handling")
        
        print("\nNext step: Increment 5 (Event Extraction with Ollama)")
        print("=" * 60 + "\n")
        
        return 0
        
    except AssertionError as e:
        print(f"\n‚ùå ASSERTION FAILED: {e}")
        return 1
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
